{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-dotenv\n",
    "#!pip install openai\n",
    "#!pip install imageio\n",
    "#!pip install azure-ai-formrecognizer\n",
    "#!pip install azure-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "import dotenv\n",
    "import os\n",
    "import base64\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "dotenv.load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "    azure_endpoint=os.getenv('AzureOpenAiEndpoint'),\n",
    "    api_key=os.getenv('AzureOpenAiKey'),\n",
    "    azure_deployment='gpt-4o',\n",
    "    api_version='2024-02-15-preview'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"aspirine.jpg\", \"rb\") as image_file:\n",
    "    aspirine = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "with open(\"flowchart.png\", \"rb\") as image_file:\n",
    "    flowchart = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "with open(\"flowchart2.jpg\", \"rb\") as image_file:\n",
    "    flowchart2 = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "with open(\"rag.png\", \"rb\") as image_file:\n",
    "    rag = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "with open(\"tablet.jpg\", \"rb\") as image_file:\n",
    "    tablet = base64.b64encode(image_file.read()).decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_document_png(encoded_image,prompt):\n",
    "    res = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/png;base64,{encoded_image}\"}\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    return res.choices[0].message.content\n",
    "\n",
    "def analyze_document_jpg(encoded_image,prompt):\n",
    "    res = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/jpg;base64,{encoded_image}\"}\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    return res.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The image shows a package of Aspirin tablets. Here are the details visible:\\n\\n- **Brand Name**: The large text at the top center of the package reads \"ASPIRINE\" in bold, black letters.\\n- **Dosage**: The dosage is indicated as \"500 mg\" in black text aligned to the right of the brand name.\\n- **Tablets Information**: It states that each tablet contains \"500 mg acetylsalicylzuur.\"\\n- **Quantity**: The package contains \"20 tabletten.\"\\n- **Manufacturer**: The bottom left side of the package has a green circular logo which says \"BAYER\" in white letters. \\n- **Language**: The instructions appear to be in Dutch. The instruction says: \"Wijze van gebruik: De tablet(ten) met een ruime hoeveelheid water na een maaltijd innemen.\" This translates to \"Method of use: Take the tablet(s) with a generous amount of water after a meal.\"\\n- **Visuals**: Toward the right side, there is an image showing two white tablets with markings \"0,5\" on them.\\n- **Color Scheme**: The package primarily uses green and white colors with black text.\\n\\nThe overall look is professional and straightforward, with distinct branding and clear dosage information.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = 'Describe the given picture with as much as details as possible'\n",
    "analyze_document_jpg(aspirine, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The flowchart illustrates the recruitment process flow, starting from defining the job description and ending with hiring the candidate. The steps in the process are as follows:\\n\\n1. **Define job description**:\\n    - The process begins with defining the job description.\\n\\n2. **Request personnel to HR**:\\n    - The personnel request is sent to HR.\\n\\n3. **Classify job hiring**:\\n    - The job hiring is classified.\\n\\n4. **Is it a regular process?**\\n    - If the process is regular, proceed to create a job posting.\\n    - If not, follow a special hiring process which involves:\\n        - Reviewing the previous candidate.\\n        - If the candidate is suitable, set up a meeting.\\n        - If not, make a hiring plan.\\n        - Create a job posting online.\\n        - Collect submitted resumes.\\n        - Assess if the candidate is qualified.\\n        - If the candidate is not qualified, they are not hired.\\n\\n5. **Create job posting**:\\n    - A job posting is created.\\n\\n6. **Found a suitable candidate?**\\n    - If a suitable candidate is found, set up a meeting.\\n    - If not, review previous candidates.\\n        - If the reviewed candidate is suitable, proceed to set up a meeting.\\n        - If not, follow the special hiring process described above.\\n\\n7. **Setup a meeting with candidate**:\\n    - A meeting with the candidate is set up.\\n\\n8. **Conduct initial interview**:\\n    - The initial interview is conducted.\\n\\n9. **List all interview questions**:\\n    - All interview questions are listed.\\n\\n10. **Conduct final interview**:\\n    - The final interview is conducted.\\n\\n11. **Reference checked?**\\n    - If references are not checked, the candidate is not hired.\\n    - If references are checked, proceed to shortlist the candidate.\\n\\n12. **Shortlist the candidate**:\\n    - The candidate is shortlisted.\\n\\n13. **Finalize job rate**:\\n    - The job rate is finalized.\\n\\n14. **Send job offer**:\\n    - The job offer is sent.\\n\\n15. **Candidate accept the offer?**\\n    - If the candidate does not accept the offer, they are not hired.\\n    - If the candidate accepts the offer, they are hired.\\n\\nThis flowchart provides a comprehensive guide to the recruitment process, ensuring a systematic approach to identifying and hiring the best candidate for the job.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = 'Describe the given flowchart as best as you can.'\n",
    "analyze_document_png(flowchart, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This flowchart is titled \"Flussdiagramm\" (which is \"Flowchart\" in English) and depicts a sequence of processes leading from an input to an output. Here is a description of the flowchart step by step:\\n\\n1. **Input**: The process starts with an \"Input\" (Vorgabe).\\n2. **Process Step 1 (Prozessschritt 1)**: The input leads to the first process step.\\n3. **Document Creation**: After Process Step 1, a document (Dokument) is generated.\\n4. **Condition Check (Bedingung)**: The flow then reaches a decision point (diamond shape labeled \"Bedingung erf√ºllt?\", which means \"Condition met?\").\\n   - If the condition is met (\"ja\"), the flow proceeds to Process Step 2.\\n   - If the condition is not met (\"nein\"), the flow goes to a different process (labelled \"Prozess\").\\n5. **Process Step 2 (Prozessschritt 2)**: If the condition is met, Process Step 2 is carried out.\\n6. **Document Creation**: Another document is generated after Process Step 2.\\n7. **Process Step 3 (Prozessschritt 3)**: The flow advances to Process Step 3.\\n8. **File Creation**: After Process Step 3, a file (Datei) is created.\\n9. **Output**: The process concludes with an \"Output\" (Ergebnis).\\n\\nThe flowchart visually represents the progression and decision-making involved in a specific process, indicating the steps and resulting documentation or files created along the way.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = 'Describe the given flowchart as best as you can.'\n",
    "analyze_document_jpg(flowchart2, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This IT architecture diagram provides a detailed overview of a Retrieval Augmented Generation (RAG) system with embeddings. It explains the flow from a user's query to the retrieval and generation of the answer, utilizing both a knowledge base and a large language model. Here's a breakdown of the various components and their interactions:\\n\\n1. **User Interaction:**\\n   - **User Question:** The process starts with a user question. This can be a query input on a device like a mobile or web interface.\\n\\n2. **RAG System:**\\n   - **Retriever over Knowledge Base:**\\n     - The user question is sent as a query to a retriever system that searches over a knowledge base.\\n     - Next, the query is sent to two main components simultaneously: \\n       1. **Large Language Model (Embedding):**\\n          - The query is embedded into a vector using a large language model.\\n          - The embedded vectors are then used to find related vectors within the knowledge base.\\n       2. **Search Index:**\\n          - The query is also sent to a search index, which returns search results corresponding to the embedded vectors and the original query.\\n\\n     - The retriever combines these search results and sends them back to the RAG system.\\n\\n3. **Generator:**\\n   - **Prompt + Knowledge:** \\n     - The search results (prompt and knowledge) are then passed to a large language model (chat).\\n   - **Response Generation:**\\n     - This large language model processes the inputs and generates a response.\\n     - The generated response is then sent back to the user as the answer.\\n\\nEach interaction is specifically designed to efficiently retrieve and generate relevant content, using both embedded vectors and indexed search results to ensure high-quality responses. The architecture ensures that user queries are handled with a combination of retrieval (searching for relevant content) and generation (producing suitable responses), grounded in a robust embedding system.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = 'Describe the given IT Architecture as best as possible. Include as many information as possible from the picture.'\n",
    "analyze_document_png(rag, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The image shows a close-up view of a pair of hands. The right hand is open with the palm facing up, holding a single yellow capsule-shaped pill. The left hand is holding a clear glass of water, with some reflections visible on the glass from the light. The background is a smooth, white surface, and there are shadows and light patterns visible, suggesting natural or bright lighting from a window or another source. The overall composition focuses on the hands, the pill, and the glass of water, emphasizing the act of preparing to take medication. The veins and contours of the hands are noticeable, highlighting a natural and realistic appearance.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = 'Describe the given picture with as much as details as possible'\n",
    "analyze_document_jpg(tablet, prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
